#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Feb  9 16:10:18 2023

@author: emielkoridon
"""

import pennylane as qml
import torch

# from functorch import jacfwd, hessian
from torch.autograd.functional import jacobian, hessian

from auto_oo.oo_pqc import OO_pqc
from auto_oo.pqc import Parameterized_circuit
from auto_oo.moldata_pyscf import Moldata_pyscf
from auto_oo.utils.newton_raphson import NewtonStep


class Noisy_OO_pqc(OO_pqc):
    def __init__(
        self,
        pqc: Parameterized_circuit,
        mol: Moldata_pyscf,
        ncas,
        nelecas,
        oao_mo_coeff=None,
        freeze_active=False,
    ):
        """
        Orbital Optimized energy class for extracting energies by computing RDMs
        from a quantum state generated by a quantum circuit. Can compute composite
        gradients and hessians with respect to both orbital and quantum circuit
        parameters.

        Args:
            pqc: Parameterized_circuit class containing the ansatz and the method
                to extract the state and the RDMs
            mol: Moldata_pyscf class containing molecular information like
                geometry, AO basis, MO basis and 1e- and 2e-integrals
            ncas: Number of active orbitals
            nelecas: Number of active electrons
            oao_mo_coeff (default None): Reference OAO-MO coefficients (ndarray)
            freeze_active (default: False):
                Freeze active-active orbital rotations
        """
        super().__init__(
            pqc, mol, ncas, nelecas, oao_mo_coeff=oao_mo_coeff, freeze_active=freeze_active
        )

    def noisy_circuit_gradient(self, theta, variance):
        exact_gradient = self.circuit_gradient(theta)
        noisy_gradient = exact_gradient + (variance**0.5) * torch.randn_like(exact_gradient)
        return noisy_gradient

    def noisy_orbital_gradient(self, theta, variance):
        exact_gradient = self.orbital_gradient(theta)
        noisy_gradient = exact_gradient + (variance**0.5) * torch.randn_like(exact_gradient)
        return noisy_gradient

    def noisy_circuit_circuit_hessian(self, theta, variance):
        exact_hessian = self.circuit_circuit_hessian(theta)
        noisy_hessian = exact_hessian + (variance**0.5) * torch.randn_like(exact_hessian)
        return noisy_hessian

    def noisy_orbital_circuit_hessian(self, theta, variance):
        exact_mixed_hessian = self.orbital_circuit_hessian(theta)
        noisy_mixed_hessian = exact_mixed_hessian + (variance**0.5) * torch.randn_like(
            exact_mixed_hessian
        )
        return noisy_mixed_hessian

    def noisy_orbital_orbital_hessian(self, theta, variance):
        exact_orbital_orbital_hessian = self.orbital_orbital_hessian(theta)
        noisy_orbital_orbital_hessian = exact_orbital_orbital_hessian + (
            variance**0.5
        ) * torch.randn_like(exact_orbital_orbital_hessian)
        return noisy_orbital_orbital_hessian

    def full_noisy_gradient(self, theta, variance):
        return torch.cat(
            (
                self.noisy_circuit_gradient(theta, variance),
                self.noisy_orbital_gradient(theta, variance),
            )
        )

    def full_noisy_hessian(self, theta, variance):
        hessian_vqe_vqe = self.noisy_circuit_circuit_hessian(theta, variance)
        hessian_vqe_oo = self.noisy_orbital_circuit_hessian(theta, variance)
        hessian_oo_oo = self.noisy_orbital_orbital_hessian(theta, variance)
        hess = torch.cat(
            (
                torch.cat((hessian_vqe_vqe, hessian_vqe_oo.t()), dim=1),
                torch.cat((hessian_vqe_oo, hessian_oo_oo), dim=1),
            ),
            dim=0,
        )
        return hess

    def full_noisy_optimization(
        self, theta_init, max_iterations=50, conv_tol=1e-10, verbose=0, **kwargs
    ):
        opt = NewtonStep(verbose=verbose, **kwargs)
        energy_init = self.energy_from_parameters(theta_init).item()
        if verbose is not None:
            print(f"iter = 000, energy = {energy_init:.12f}")

        theta_l = []
        kappa_l = []
        oao_mo_coeff_l = []
        energy_l = []
        hess_eig_l = []

        theta = theta_init.detach().clone()
        for n in range(max_iterations):

            kappa = torch.zeros(self.n_kappa)

            grad = self.full_noisy_gradient(theta)
            hess = self.full_noisy_hessian(theta)

            new_theta_kappa, hess_eig = opt.damped_newton_step(
                self.energy_from_parameters, (theta, kappa), grad, hess
            )

            hess_eig_l.append(hess_eig)

            theta = new_theta_kappa[0]
            kappa = new_theta_kappa[1]

            theta_l.append(theta.detach().clone())
            kappa_l.append(kappa.detach().clone())

            self.oao_mo_coeff = self.oao_mo_coeff @ self.kappa_to_mo_coeff(kappa)

            oao_mo_coeff_l.append(self.oao_mo_coeff.detach().clone())

            energy = self.energy_from_parameters(theta).item()
            energy_l.append(energy)

            if verbose is not None:
                print(f"iter = {n+1:03}, energy = {energy:.12f}")
            if n > 1:
                if abs(energy_l[-1] - energy_l[-2]) < conv_tol:
                    if verbose is not None:
                        print("optimization finished.")
                        print("E_fin =", energy_l[-1])
                    break

        return energy_l, theta_l, kappa_l, oao_mo_coeff_l, hess_eig_l
